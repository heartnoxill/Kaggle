{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Procedure\n1. Import libraries\n2. Import data\n3. Data analysis (look for missing/corrupted values)\n4. Data visualization (maybe of each feature)\n5. Data cleaning\n6. Test different models and choose the best\n7. kaggle --> create submission file","metadata":{}},{"cell_type":"markdown","source":"## 1. Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-08T07:50:02.358007Z","iopub.execute_input":"2021-09-08T07:50:02.358409Z","iopub.status.idle":"2021-09-08T07:50:02.804654Z","shell.execute_reply.started":"2021-09-08T07:50:02.358354Z","shell.execute_reply":"2021-09-08T07:50:02.803383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Import data","metadata":{}},{"cell_type":"code","source":"# Import data using Pandas\ntrain = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')\n\n# Let's look at training data\ntrain.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:02.810963Z","iopub.execute_input":"2021-09-08T07:50:02.811327Z","iopub.status.idle":"2021-09-08T07:50:02.85289Z","shell.execute_reply.started":"2021-09-08T07:50:02.811288Z","shell.execute_reply":"2021-09-08T07:50:02.851849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Data analysis","metadata":{}},{"cell_type":"code","source":"# Check datatypes\ntrain.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:02.854781Z","iopub.execute_input":"2021-09-08T07:50:02.855089Z","iopub.status.idle":"2021-09-08T07:50:02.863731Z","shell.execute_reply.started":"2021-09-08T07:50:02.855058Z","shell.execute_reply":"2021-09-08T07:50:02.862742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe(include=\"all\").T","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:02.865174Z","iopub.execute_input":"2021-09-08T07:50:02.865445Z","iopub.status.idle":"2021-09-08T07:50:02.925621Z","shell.execute_reply.started":"2021-09-08T07:50:02.865419Z","shell.execute_reply":"2021-09-08T07:50:02.924553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary\n- We have 891 passengers\n- Age count = 714 --> 19.8% missing (must fix)\n- Cabin count = 204 --> 76% missing (must fix!!!)\n- embarked = 889 --> 0.22% missing (can be neglected)","metadata":{}},{"cell_type":"code","source":"# Count for missing value in training data\nprint(pd.isnull(train).sum())","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:02.927559Z","iopub.execute_input":"2021-09-08T07:50:02.928005Z","iopub.status.idle":"2021-09-08T07:50:02.937417Z","shell.execute_reply.started":"2021-09-08T07:50:02.927941Z","shell.execute_reply":"2021-09-08T07:50:02.936075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## We can see that the counts = describe value. Thus, there are no NaN value (only missing value)","metadata":{}},{"cell_type":"markdown","source":"## 4. Data visualization","metadata":{}},{"cell_type":"code","source":"# Barplot of survivors by sex\nsns.barplot(x=\"Sex\", y=\"Survived\", data=train)\n\n# Print percentages of females vs. males that survive\nprint(\"Percentage of females who survived:\", train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of males who survived:\", train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts(normalize = True)[1]*100)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:02.93915Z","iopub.execute_input":"2021-09-08T07:50:02.939563Z","iopub.status.idle":"2021-09-08T07:50:03.160928Z","shell.execute_reply.started":"2021-09-08T07:50:02.939517Z","shell.execute_reply":"2021-09-08T07:50:03.160187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Survivors are most likely female --> Sex feature is important in prediction","metadata":{}},{"cell_type":"code","source":"# Pclass = Passenger class\n# Barplot of survivors by passenger class\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=train)\n\n# Print percentage of survivors by Pclass\nprint(\"Percentage of Pclass = 1 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 1].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of Pclass = 2 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 2].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of Pclass = 3 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 3].value_counts(normalize = True)[1]*100)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:03.162018Z","iopub.execute_input":"2021-09-08T07:50:03.162434Z","iopub.status.idle":"2021-09-08T07:50:03.382416Z","shell.execute_reply.started":"2021-09-08T07:50:03.162388Z","shell.execute_reply":"2021-09-08T07:50:03.381611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## First-class is more likely to survive than second, and third class","metadata":{}},{"cell_type":"code","source":"# People with relatives (parents and children)\nsns.barplot(x=\"Parch\", y=\"Survived\", data=train)\n\n# Print percentage of survivors by Parch\nprint(\"Percentage of Parch = 1 who survived:\", train[\"Survived\"][train[\"Parch\"] == 1].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of Parch = 2 who survived:\", train[\"Survived\"][train[\"Parch\"] == 2].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of Parch = 3 who survived:\", train[\"Survived\"][train[\"Parch\"] == 3].value_counts(normalize = True)[1]*100)\n# print(\"Percentage of Parch = 4 who survived:\", train[\"Survived\"][train[\"Parch\"] == 4].value_counts(normalize = True)[1]*100) # <-- No Parch = 4\nprint(\"Percentage of Parch = 5 who survived:\", train[\"Survived\"][train[\"Parch\"] == 5].value_counts(normalize = True)[1]*100)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:03.384577Z","iopub.execute_input":"2021-09-08T07:50:03.385115Z","iopub.status.idle":"2021-09-08T07:50:03.692987Z","shell.execute_reply.started":"2021-09-08T07:50:03.385008Z","shell.execute_reply":"2021-09-08T07:50:03.692048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ## People with < 4 relatives are likely to survive than people with >= 4 relative\n* ## But people with no relatives are less likely to survive compared to people with 1-3 relatives","metadata":{}},{"cell_type":"code","source":"# Age feature\n# Fill missing values with -0.5\ntrain[\"Age\"] = train[\"Age\"].fillna(-0.5)\ntest[\"Age\"] = test[\"Age\"].fillna(-0.5)\n\n# Create bins for age ranges separation\nbins = [-1, 0, 5, 12, 18, 24, 35, 60, np.inf]\n\n# Label of age ranges\nlabels = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n\n# Assign labels to bins\ntrain['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = labels)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = labels)\n\n# Plot barplot of Age vs. survival\nsns.barplot(x=\"AgeGroup\", y=\"Survived\", data=train)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:03.694567Z","iopub.execute_input":"2021-09-08T07:50:03.69501Z","iopub.status.idle":"2021-09-08T07:50:04.082714Z","shell.execute_reply.started":"2021-09-08T07:50:03.694963Z","shell.execute_reply":"2021-09-08T07:50:04.081985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baby is the most likely to survive.","metadata":{}},{"cell_type":"code","source":"# Cabin feature\n\ntrain[\"CabinBool\"] = (train[\"Cabin\"].notnull().astype('int'))\ntest[\"CabinBool\"] = (test[\"Cabin\"].notnull().astype('int'))\n\n# Calculate percentages of CabinBool vs. survived\nprint(\"Percentage of CabinBool = 1 who survived:\", train[\"Survived\"][train[\"CabinBool\"] == 1].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of CabinBool = 0 who survived:\", train[\"Survived\"][train[\"CabinBool\"] == 0].value_counts(normalize = True)[1]*100)\n\n# Plot barplot of CabinBool vs. survival\nsns.barplot(x=\"CabinBool\", y=\"Survived\", data=train)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:04.083708Z","iopub.execute_input":"2021-09-08T07:50:04.084127Z","iopub.status.idle":"2021-09-08T07:50:04.259229Z","shell.execute_reply.started":"2021-09-08T07:50:04.084093Z","shell.execute_reply":"2021-09-08T07:50:04.258199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ## People with recorded cabin number are more likely to survive\n* ## \"people with recorded cabin numbers are of higher socioeconomic class, and thus more likely to survive\"","metadata":{}},{"cell_type":"markdown","source":"## 5. Data cleaning","metadata":{}},{"cell_type":"code","source":"# Look at test data\ntest.describe(include=\"all\").T","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:04.260478Z","iopub.execute_input":"2021-09-08T07:50:04.260762Z","iopub.status.idle":"2021-09-08T07:50:04.308633Z","shell.execute_reply.started":"2021-09-08T07:50:04.260733Z","shell.execute_reply":"2021-09-08T07:50:04.307746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary of test data\n- 418 passenger\n- fare count 417 --> 0.24% missing (1 value is missing)\n- cabin count 91 --> 78.23% misssing","metadata":{}},{"cell_type":"code","source":"# Cabin feature is not very useful --> We will drop it\ntrain = train.drop(['Cabin'], axis = 1)\ntest = test.drop(['Cabin'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:04.310022Z","iopub.execute_input":"2021-09-08T07:50:04.310299Z","iopub.status.idle":"2021-09-08T07:50:04.317006Z","shell.execute_reply.started":"2021-09-08T07:50:04.310272Z","shell.execute_reply":"2021-09-08T07:50:04.316202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We can drop Ticket feature too\ntrain = train.drop(['Ticket'], axis = 1)\ntest = test.drop(['Ticket'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:04.318348Z","iopub.execute_input":"2021-09-08T07:50:04.318615Z","iopub.status.idle":"2021-09-08T07:50:04.339367Z","shell.execute_reply.started":"2021-09-08T07:50:04.318589Z","shell.execute_reply":"2021-09-08T07:50:04.33832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Embarked feature\n# print(train['Embarked'].unique) # S, C, Q\n\nprint(\"Number of people embarking in Southampton (S):\")\nsouthampton = train[train[\"Embarked\"] == \"S\"].shape[0]\nprint(southampton)\n\nprint(\"Number of people embarking in Cherbourg (C):\")\ncherbourg = train[train[\"Embarked\"] == \"C\"].shape[0]\nprint(cherbourg)\n\nprint(\"Number of people embarking in Queenstown (Q):\")\nqueenstown = train[train[\"Embarked\"] == \"Q\"].shape[0]\nprint(queenstown)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:04.34044Z","iopub.execute_input":"2021-09-08T07:50:04.340867Z","iopub.status.idle":"2021-09-08T07:50:04.354551Z","shell.execute_reply.started":"2021-09-08T07:50:04.340835Z","shell.execute_reply":"2021-09-08T07:50:04.353144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Majority of people embarked in Southampton --> So, we will replace missing value with S.","metadata":{}},{"cell_type":"code","source":"# Replacing the missing values in the Embarked feature with S\ntrain = train.fillna({\"Embarked\": \"S\"})","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:04.356213Z","iopub.execute_input":"2021-09-08T07:50:04.356631Z","iopub.status.idle":"2021-09-08T07:50:04.365899Z","shell.execute_reply.started":"2021-09-08T07:50:04.356585Z","shell.execute_reply":"2021-09-08T07:50:04.36482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Age feature\n# Create a combined group of both datasets\ncombine = [train, test]\n\n# Extract a title for each Name in the train and test datasets\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train['Title'], train['Sex'])","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:04.367375Z","iopub.execute_input":"2021-09-08T07:50:04.367948Z","iopub.status.idle":"2021-09-08T07:50:04.403521Z","shell.execute_reply.started":"2021-09-08T07:50:04.367914Z","shell.execute_reply":"2021-09-08T07:50:04.402686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace various titles with more common title\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Capt', 'Col',\n    'Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n    \n    dataset['Title'] = dataset['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\ntrain[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:04.404751Z","iopub.execute_input":"2021-09-08T07:50:04.405177Z","iopub.status.idle":"2021-09-08T07:50:04.433305Z","shell.execute_reply.started":"2021-09-08T07:50:04.405135Z","shell.execute_reply":"2021-09-08T07:50:04.432397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Map each of the title groups to a numerical value\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 6}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:04.434728Z","iopub.execute_input":"2021-09-08T07:50:04.435087Z","iopub.status.idle":"2021-09-08T07:50:04.456674Z","shell.execute_reply.started":"2021-09-08T07:50:04.435046Z","shell.execute_reply":"2021-09-08T07:50:04.455468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Try to predict the missing Age values from the most common age for their Title.\n\n# fill missing age with mode age group for each title\nmr_age = train[train[\"Title\"] == 1][\"AgeGroup\"].mode() #Young Adult\nmiss_age = train[train[\"Title\"] == 2][\"AgeGroup\"].mode() #Student\nmrs_age = train[train[\"Title\"] == 3][\"AgeGroup\"].mode() #Adult\nmaster_age = train[train[\"Title\"] == 4][\"AgeGroup\"].mode() #Baby\nroyal_age = train[train[\"Title\"] == 5][\"AgeGroup\"].mode() #Adult\nrare_age = train[train[\"Title\"] == 6][\"AgeGroup\"].mode() #Adult\n\nage_title_mapping = {1: \"Young Adult\", 2: \"Student\", 3: \"Adult\", 4: \"Baby\", 5: \"Adult\", 6: \"Adult\"}\n\n# train = train.fillna({\"Age\": train[\"Title\"].map(age_title_mapping)})\n# test = test.fillna({\"Age\": test[\"Title\"].map(age_title_mapping)})\n\nfor x in range(len(train[\"AgeGroup\"])):\n    if train[\"AgeGroup\"][x] == \"Unknown\":\n        train[\"AgeGroup\"][x] = age_title_mapping[train[\"Title\"][x]]\n        \nfor x in range(len(test[\"AgeGroup\"])):\n    if test[\"AgeGroup\"][x] == \"Unknown\":\n        test[\"AgeGroup\"][x] = age_title_mapping[test[\"Title\"][x]]","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:04.458758Z","iopub.execute_input":"2021-09-08T07:50:04.459214Z","iopub.status.idle":"2021-09-08T07:50:04.614408Z","shell.execute_reply.started":"2021-09-08T07:50:04.459168Z","shell.execute_reply":"2021-09-08T07:50:04.613394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Map each Age value to a numerical value\nage_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\ntrain['AgeGroup'] = train['AgeGroup'].map(age_mapping)\ntest['AgeGroup'] = test['AgeGroup'].map(age_mapping)\n\ntrain.head(10)\n\n# Dropping the Age feature for now, might change\n# train = train.drop(['Age'], axis = 1)\n# test = test.drop(['Age'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:04.615774Z","iopub.execute_input":"2021-09-08T07:50:04.616073Z","iopub.status.idle":"2021-09-08T07:50:04.639948Z","shell.execute_reply.started":"2021-09-08T07:50:04.616043Z","shell.execute_reply":"2021-09-08T07:50:04.638888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the name feature since it contains no more useful information.\ntrain = train.drop(['Name'], axis = 1)\ntest = test.drop(['Name'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:04.641308Z","iopub.execute_input":"2021-09-08T07:50:04.641593Z","iopub.status.idle":"2021-09-08T07:50:04.648834Z","shell.execute_reply.started":"2021-09-08T07:50:04.641567Z","shell.execute_reply":"2021-09-08T07:50:04.64769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Map each Sex value to a numerical value\nsex_mapping = {\"male\": 0, \"female\": 1}\ntrain['Sex'] = train['Sex'].map(sex_mapping)\ntest['Sex'] = test['Sex'].map(sex_mapping)\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:04.650081Z","iopub.execute_input":"2021-09-08T07:50:04.650359Z","iopub.status.idle":"2021-09-08T07:50:04.678895Z","shell.execute_reply.started":"2021-09-08T07:50:04.650332Z","shell.execute_reply":"2021-09-08T07:50:04.67771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Map each Embarked value to a numerical value\nembarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\ntrain['Embarked'] = train['Embarked'].map(embarked_mapping)\ntest['Embarked'] = test['Embarked'].map(embarked_mapping)\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:04.68018Z","iopub.execute_input":"2021-09-08T07:50:04.680453Z","iopub.status.idle":"2021-09-08T07:50:04.705584Z","shell.execute_reply.started":"2021-09-08T07:50:04.680426Z","shell.execute_reply":"2021-09-08T07:50:04.704561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping the Age feature for now, might change\ntrain = train.drop(['Age'], axis = 1)\ntest = test.drop(['Age'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:50:26.083026Z","iopub.execute_input":"2021-09-08T07:50:26.083386Z","iopub.status.idle":"2021-09-08T07:50:26.091088Z","shell.execute_reply.started":"2021-09-08T07:50:26.083356Z","shell.execute_reply":"2021-09-08T07:50:26.089984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fare feature --> Separate into logical groups\n# Fill in missing Fare value in test set based on mean fare for that Pclass \nfor x in range(len(test[\"Fare\"])):\n    if pd.isnull(test[\"Fare\"][x]):\n        pclass = test[\"Pclass\"][x] #Pclass = 3\n        test[\"Fare\"][x] = round(train[train[\"Pclass\"] == pclass][\"Fare\"].mean(), 4) # Round from pclass = 3's fare\n        \n# Map Fare values into groups of numerical values\n\n\"\"\"pd.qcut = Discretize variable into equal-sized buckets based on rank or based on sample quantiles. \nFor example 1000 values for 10 quantiles would produce a Categorical object indicating quantile membership for each data point.\"\"\"\n\ntrain['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1, 2, 3, 4])\ntest['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1, 2, 3, 4])\n\n# Drop Fare values (we use FareBand instead)\ntrain = train.drop(['Fare'], axis = 1)\ntest = test.drop(['Fare'], axis = 1)\n\n# Check train data\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:54:12.048769Z","iopub.execute_input":"2021-09-08T07:54:12.049178Z","iopub.status.idle":"2021-09-08T07:54:12.083051Z","shell.execute_reply.started":"2021-09-08T07:54:12.049142Z","shell.execute_reply":"2021-09-08T07:54:12.082067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check test data\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:54:16.178628Z","iopub.execute_input":"2021-09-08T07:54:16.178991Z","iopub.status.idle":"2021-09-08T07:54:16.193773Z","shell.execute_reply.started":"2021-09-08T07:54:16.178947Z","shell.execute_reply":"2021-09-08T07:54:16.192541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Test different models and choose the best one\nSplitting the Training Data\n* We will use part of our training data (22% in this case) to test the accuracy of our different models.","metadata":{}},{"cell_type":"code","source":"# Train and validate value split\nfrom sklearn.model_selection import train_test_split\n\npredictors = train.drop(['Survived', 'PassengerId'], axis=1)\ntarget = train[\"Survived\"]\nx_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.22, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T07:57:50.682696Z","iopub.execute_input":"2021-09-08T07:57:50.683093Z","iopub.status.idle":"2021-09-08T07:57:50.889365Z","shell.execute_reply.started":"2021-09-08T07:57:50.683056Z","shell.execute_reply":"2021-09-08T07:57:50.888571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing different models\n* Gaussian Naive Bayes\n* Logistic Regression\n* Support Vector Machines\n* Perceptron\n* Decision Tree Classifier\n* Random Forest Classifier\n* KNN or k-Nearest Neighbors\n* Stochastic Gradient Descent\n* Gradient Boosting Classifier\n\nFor each model, we set the model, fit it with 80% of our training data, predict for 20% of the training data and check the accuracy.","metadata":{}},{"cell_type":"code","source":"# Gaussian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\n\ngaussian = GaussianNB()\ngaussian.fit(x_train, y_train)\ny_pred = gaussian.predict(x_val)\nacc_gaussian = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_gaussian)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T08:00:22.289531Z","iopub.execute_input":"2021-09-08T08:00:22.289916Z","iopub.status.idle":"2021-09-08T08:00:22.308626Z","shell.execute_reply.started":"2021-09-08T08:00:22.289884Z","shell.execute_reply":"2021-09-08T08:00:22.30761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_val)\nacc_logreg = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_logreg)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T08:00:37.569069Z","iopub.execute_input":"2021-09-08T08:00:37.569426Z","iopub.status.idle":"2021-09-08T08:00:37.923285Z","shell.execute_reply.started":"2021-09-08T08:00:37.569392Z","shell.execute_reply":"2021-09-08T08:00:37.922493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Support Vector Machines\nfrom sklearn.svm import SVC\n\nsvc = SVC()\nsvc.fit(x_train, y_train)\ny_pred = svc.predict(x_val)\nacc_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_svc)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T08:00:45.01739Z","iopub.execute_input":"2021-09-08T08:00:45.018034Z","iopub.status.idle":"2021-09-08T08:00:45.047229Z","shell.execute_reply.started":"2021-09-08T08:00:45.017995Z","shell.execute_reply":"2021-09-08T08:00:45.046265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Linear SVC\nfrom sklearn.svm import LinearSVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(x_train, y_train)\ny_pred = linear_svc.predict(x_val)\nacc_linear_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_linear_svc)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T08:00:51.064063Z","iopub.execute_input":"2021-09-08T08:00:51.064732Z","iopub.status.idle":"2021-09-08T08:00:51.10527Z","shell.execute_reply.started":"2021-09-08T08:00:51.064695Z","shell.execute_reply":"2021-09-08T08:00:51.104383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perceptron\nfrom sklearn.linear_model import Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(x_train, y_train)\ny_pred = perceptron.predict(x_val)\nacc_perceptron = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_perceptron)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T08:00:55.868037Z","iopub.execute_input":"2021-09-08T08:00:55.868558Z","iopub.status.idle":"2021-09-08T08:00:55.884239Z","shell.execute_reply.started":"2021-09-08T08:00:55.868518Z","shell.execute_reply":"2021-09-08T08:00:55.883115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\n\ndecisiontree = DecisionTreeClassifier()\ndecisiontree.fit(x_train, y_train)\ny_pred = decisiontree.predict(x_val)\nacc_decisiontree = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_decisiontree)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T08:01:01.595516Z","iopub.execute_input":"2021-09-08T08:01:01.595859Z","iopub.status.idle":"2021-09-08T08:01:01.729909Z","shell.execute_reply.started":"2021-09-08T08:01:01.595826Z","shell.execute_reply":"2021-09-08T08:01:01.728763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(x_train, y_train)\ny_pred = randomforest.predict(x_val)\nacc_randomforest = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_randomforest)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T08:01:06.65061Z","iopub.execute_input":"2021-09-08T08:01:06.650958Z","iopub.status.idle":"2021-09-08T08:01:06.867129Z","shell.execute_reply.started":"2021-09-08T08:01:06.650928Z","shell.execute_reply":"2021-09-08T08:01:06.866017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# KNN or k-Nearest Neighbors\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(x_train, y_train)\ny_pred = knn.predict(x_val)\nacc_knn = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_knn)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T08:01:12.023368Z","iopub.execute_input":"2021-09-08T08:01:12.023727Z","iopub.status.idle":"2021-09-08T08:01:12.049987Z","shell.execute_reply.started":"2021-09-08T08:01:12.023699Z","shell.execute_reply":"2021-09-08T08:01:12.048685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stochastic Gradient Descent\nfrom sklearn.linear_model import SGDClassifier\n\nsgd = SGDClassifier()\nsgd.fit(x_train, y_train)\ny_pred = sgd.predict(x_val)\nacc_sgd = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_sgd)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T08:01:17.071243Z","iopub.execute_input":"2021-09-08T08:01:17.071592Z","iopub.status.idle":"2021-09-08T08:01:17.086016Z","shell.execute_reply.started":"2021-09-08T08:01:17.071561Z","shell.execute_reply":"2021-09-08T08:01:17.085203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Gradient Boosting Classifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier()\ngbk.fit(x_train, y_train)\ny_pred = gbk.predict(x_val)\nacc_gbk = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_gbk)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T08:01:22.21865Z","iopub.execute_input":"2021-09-08T08:01:22.219045Z","iopub.status.idle":"2021-09-08T08:01:22.324004Z","shell.execute_reply.started":"2021-09-08T08:01:22.219001Z","shell.execute_reply":"2021-09-08T08:01:22.32287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's compare the accuracies of each model!\n\nmodels = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', 'Linear SVC', \n              'Decision Tree', 'Stochastic Gradient Descent', 'Gradient Boosting Classifier'],\n    'Score': [acc_svc, acc_knn, acc_logreg, \n              acc_randomforest, acc_gaussian, acc_perceptron,acc_linear_svc, acc_decisiontree,\n              acc_sgd, acc_gbk]})\nmodels.sort_values(by='Score', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T08:01:37.863609Z","iopub.execute_input":"2021-09-08T08:01:37.863961Z","iopub.status.idle":"2021-09-08T08:01:37.879491Z","shell.execute_reply.started":"2021-09-08T08:01:37.86393Z","shell.execute_reply":"2021-09-08T08:01:37.878183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gradient Boosting Classifier has the highest score, we will choose this one.","metadata":{}},{"cell_type":"markdown","source":"## 7. Submission file creation","metadata":{}},{"cell_type":"code","source":"#set ids as PassengerId and predict survival \nids = test['PassengerId']\npredictions = gbk.predict(test.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T08:02:56.660751Z","iopub.execute_input":"2021-09-08T08:02:56.661147Z","iopub.status.idle":"2021-09-08T08:02:56.677766Z","shell.execute_reply.started":"2021-09-08T08:02:56.661113Z","shell.execute_reply":"2021-09-08T08:02:56.676719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}